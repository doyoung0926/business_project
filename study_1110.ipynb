{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "from yolov5facedetector.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class YoloDetector in module yolov5facedetector.face_detector:\n",
      "\n",
      "class YoloDetector(builtins.object)\n",
      " |  YoloDetector(yolo_type='yolov5n', gpu=0, min_face=100, target_size=None, frontal=False)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, *args)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, yolo_type='yolov5n', gpu=0, min_face=100, target_size=None, frontal=False)\n",
      " |      yolo_type: name of YOLOv5 Network Type.\n",
      " |          Option: - 'yolov5n' (default)\n",
      " |                  - 'yolov5m'\n",
      " |                  - 'yolov5l'            \n",
      " |      gpu : gpu number (int) or -1 or string for cpu.\n",
      " |      min_face : minimal face size in pixels.\n",
      " |      target_size : target size of smaller image axis (choose lower for faster work). e.g. 480, 720, 1080.\n",
      " |                  None for original resolution.\n",
      " |      frontal : if True tries to filter nonfrontal faces by keypoints location.\n",
      " |  \n",
      " |  get_frontal_predict(self, box, points)\n",
      " |      Make a decision whether face is frontal by keypoints.\n",
      " |      Returns:\n",
      " |          True if face is frontal, False otherwise.\n",
      " |  \n",
      " |  init_detector(self, yolo_type)\n",
      " |      Initialize Detector\n",
      " |  \n",
      " |  predict(self, imgs, conf_thres=0.3, iou_thres=0.5)\n",
      " |      Get bbox coordinates and keypoints of faces on original image.\n",
      " |      Params:\n",
      " |          imgs: image or list of images to detect faces on\n",
      " |          conf_thres: confidence threshold for each prediction\n",
      " |          iou_thres: threshold for NMS (filtering of intersecting bboxes)\n",
      " |      Returns:\n",
      " |          bboxes: list of arrays with 4 coordinates of bounding boxes with format x1,y1,x2,y2.\n",
      " |          points: list of arrays with coordinates of 5 facial keypoints (eyes, nose, lips corners).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(YoloDetector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 인식 네모 박스 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\vs코드\\wkit_vs\\study\\study_1110.ipynb 셀 5\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     webcam\u001b[39m.\u001b[39mrelease()  \u001b[39m# 동영상 파일을 닫고 메모리 해제\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()   \u001b[39m# 모든 윈도우 창을 닫음\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39mprint\u001b[39m(nemo())\n",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\vs코드\\wkit_vs\\study\\study_1110.ipynb 셀 5\u001b[0m in \u001b[0;36mnemo\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m model \u001b[39m=\u001b[39m YoloDetector(target_size\u001b[39m=\u001b[39m\u001b[39m1080\u001b[39m, gpu\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, min_face\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# yolov5n_state_dict.pt 자동 다운 됨\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# 경로 url의 비디오 정보를 반환\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m webcam \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mVideoCapture(url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# 동영상 파일 열기 성공 여부 확인\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m webcam\u001b[39m.\u001b[39misOpened():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모듈 로딩\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "from yolov5facedetector.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 기    능 : 얼굴 인식 네모 박스 함수\n",
    "# 함 수 명 : nemo\n",
    "# 파라미터 : url\n",
    "# 반 환 값 : 없음\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def nemo(url=0):\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # YoloDetector 파라미터 \n",
    "    # gpu : gpu number (int) or -1 or string for cpu.\n",
    "    # min_face : minimal face size in pixels.\n",
    "    # target_size : target size of smaller image axis (choose lower for faster work). e.g. 480, 720, 1080. None for original resolution.\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    model = YoloDetector(target_size=1080, gpu=0, min_face=0)  # yolov5n_state_dict.pt 자동 다운 됨\n",
    "\n",
    "    # 경로 url의 비디오 정보를 반환\n",
    "    webcam = cv2.VideoCapture(url)\n",
    "\n",
    "    # 동영상 파일 열기 성공 여부 확인\n",
    "    if not webcam.isOpened():\n",
    "        print(\"Could not open webcam\")  # 열려있지 않으면 문자열 출력\n",
    "        exit()\n",
    "        \n",
    "    # 비디오 매 프레임 처리\n",
    "    while webcam.isOpened():\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # webcam.read <- 프레임 읽기 메서드\n",
    "        # status : 카메라의 상태가 저장. 정상 작동 True, 비정상 작동 False 반환\n",
    "        # frame : 현재 시점의 프레임(numpy.ndarray) 저장\n",
    "        # -------------------------------------------------------------\n",
    "        status, frame = webcam.read() \n",
    "        # -------------------------------------------------------------\n",
    "        # cv2.resize <- 이미지 크기 조절 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 절대 크기 : dsize \n",
    "        # 상대 크기 : fx, fy\n",
    "        # interpolation : 보간법\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # cv2.cvtcolor <- 색상 공간 변환 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 색상 변환 코드. 원본 이미지 색상 공간2결과 이미지 색상 공간 : cv2.COLOR_BGR2RGB\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        bboxes, confs, points = model.predict(frame)\n",
    "\n",
    "        if not status:\n",
    "            print(\"Could not read frame\")\n",
    "            exit()\n",
    "\n",
    "        for idx in range(len(bboxes[0])):\n",
    "\n",
    "            (startX, startY)=bboxes[0][idx][0], bboxes[0][idx][1]\n",
    "            (endX, endY)=bboxes[0][idx][2], bboxes[0][idx][3]\n",
    "        \n",
    "            # ---------------------------------------------------------------------------------\n",
    "            # cv2.rectangle <- 사각형 그리기 함수 파라미터\n",
    "            # 입력 이미지 : frame \n",
    "            # 좌측 상단 모서리 좌표 : (startX, startY)\n",
    "            # 우측 하단 모서리 좌표 : (endX, endY)\n",
    "            # 색상 : (0, 255, 0)\n",
    "            # 두께 : 2\n",
    "            # ---------------------------------------------------------------------------------\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "        # display output\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow(\"Real-time face detection\", frame)  # 윈도우 창에 이미지를 띄움\n",
    "\n",
    "        # cv2.waitkey 키 입력 대기 함수\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q' 키 입력 받으면 윈도우 창이 종료\n",
    "            break\n",
    "        \n",
    "\n",
    "    webcam.release()  # 동영상 파일을 닫고 메모리 해제\n",
    "    cv2.destroyAllWindows()   # 모든 윈도우 창을 닫음\n",
    "\n",
    "print(nemo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moja():\n",
    "\n",
    "    model = YoloDetector(target_size=1080,gpu=0,min_face=0)\n",
    "\n",
    "    # open webcam\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not webcam.isOpened():\n",
    "        print(\"Could not open webcam\")\n",
    "        exit()\n",
    "        \n",
    "    # loop through frames\n",
    "    while webcam.isOpened():\n",
    "    \n",
    "        # read frame from webcam \n",
    "        status, frame = webcam.read()\n",
    "        \n",
    "        frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        bboxes, confs, points = model.predict(frame)\n",
    "\n",
    "        if not status:\n",
    "            print(\"Could not read frame\")\n",
    "            exit()\n",
    "    \n",
    "        for idx in range(len(bboxes[0])):\n",
    "\n",
    "            (startX, startY)=bboxes[0][idx][0], bboxes[0][idx][1]\n",
    "            (endX, endY)=bboxes[0][idx][2], bboxes[0][idx][3]\n",
    "        \n",
    "            # 모자이크 처리\n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            M = face_region.shape[0]\n",
    "            N = face_region.shape[1]\n",
    "    \n",
    "            face_region = cv2.resize(face_region, None, fx=0.05, fy=0.05, interpolation=cv2.INTER_AREA)\n",
    "            face_region = cv2.resize(face_region, (N, M), interpolation=cv2.INTER_AREA)\n",
    "            frame[startY:endY, startX:endX] = face_region\n",
    "\n",
    "        # display output\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow(\"Real-time face detection\", frame)\n",
    "    \n",
    "        # press \"Q\" to stop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    # release resources\n",
    "\n",
    "    webcam.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    "\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    "    \n",
    "\n",
    "    # display output\n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(\"Real-time face detection\", frame)\n",
    "\n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(1) == 26:\n",
    "        webcam.release()\n",
    "        # cv2.destroyAllWindows()\n",
    "        print(nemo())\n",
    "\n",
    "    if cv2.waitKey(1) == 24:\n",
    "        webcam.release()\n",
    "        # cv2.destroyAllWindows()\n",
    "        print(moja())\n",
    "    \n",
    "# release resources\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\vs코드\\wkit_vs\\study\\study_1110.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m frame\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mresize(frame, dsize\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m), fx\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, fy\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_CUBIC)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m frame\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m bboxes, confs, points \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m status:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCould not read frame\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pafy\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "from yolov5facedetector.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# import youtube_dl\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=iibjfV7_n20'\n",
    "video = pafy.new(url)\n",
    "best = video.getbest(preftype='mp4')     # 'webm','3gp'\n",
    "webcam=cv2.VideoCapture(best.url)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    " \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    bboxes, confs, points = model.predict(frame)\n",
    "\n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    " \n",
    "    for idx in range(len(bboxes[0])):\n",
    "\n",
    "        (startX, startY)=bboxes[0][idx][0], bboxes[0][idx][1]\n",
    "        (endX, endY)=bboxes[0][idx][2], bboxes[0][idx][3]\n",
    "\n",
    "        key = cv2.waitKey(33)\n",
    "\n",
    "        if key == 26:\n",
    "            # draw rectangle over face\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if key == 24:\n",
    "\n",
    "            # 모자이크 처리\n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            M = face_region.shape[0]\n",
    "            N = face_region.shape[1]\n",
    "    \n",
    "            face_region = cv2.resize(face_region, None, fx=0.05, fy=0.05, interpolation=cv2.INTER_AREA)\n",
    "            face_region = cv2.resize(face_region, (N, M), interpolation=cv2.INTER_AREA)\n",
    "            frame[startY:endY, startX:endX] = face_region\n",
    "\n",
    "            \n",
    "\n",
    "    # display output\n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(\"Real-time face detection\", frame)\n",
    " \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvlib as cv\n",
    "import cv2\n",
    "from yolov5facedetector.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# # import youtube_dl\n",
    "\n",
    "# url = 'https://www.youtube.com/watch?v=iibjfV7_n20'\n",
    "# video = pafy.new(url)\n",
    "# best = video.getbest(preftype='mp4')     # 'webm','3gp'\n",
    "# webcam=cv2.VideoCapture(best.url)\n",
    "\n",
    "# def trans(url):\n",
    "#     url = 'https://www.youtube.com/watch?v=iibjfV7_n20'\n",
    "#     video = pafy.new(url)\n",
    "#     best = video.getbest(preftype='mp4')     # 'webm','3gp'\n",
    "    \n",
    "#     return best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nemo(best=0):\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # YoloDetector 파라미터 \n",
    "    # gpu : gpu number (int) or -1 or string for cpu.\n",
    "    # min_face : minimal face size in pixels.\n",
    "    # target_size : target size of smaller image axis (choose lower for faster work). e.g. 480, 720, 1080. None for original resolution.\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    model = YoloDetector(target_size=1080, gpu=0, min_face=0)  # yolov5n_state_dict.pt 자동 다운 됨\n",
    "\n",
    "    # 경로 url의 비디오 정보를 반환\n",
    "    webcam=cv2.VideoCapture(best.url)\n",
    "    # webcam = cv2.VideoCapture(url)\n",
    "\n",
    "    # 동영상 파일 열기 성공 여부 확인\n",
    "    if not webcam.isOpened():\n",
    "        print(\"Could not open webcam\")  # 열려있지 않으면 문자열 출력\n",
    "        exit()\n",
    "        \n",
    "    # 비디오 매 프레임 처리\n",
    "    while webcam.isOpened():\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # webcam.read <- 프레임 읽기 메서드\n",
    "        # status : 카메라의 상태가 저장. 정상 작동 True, 비정상 작동 False 반환\n",
    "        # frame : 현재 시점의 프레임(numpy.ndarray) 저장\n",
    "        # -------------------------------------------------------------\n",
    "        status, frame = webcam.read() \n",
    "        # -------------------------------------------------------------\n",
    "        # cv2.resize <- 이미지 크기 조절 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 절대 크기 : dsize \n",
    "        # 상대 크기 : fx, fy\n",
    "        # interpolation : 보간법\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # cv2.cvtcolor <- 색상 공간 변환 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 색상 변환 코드. 원본 이미지 색상 공간2결과 이미지 색상 공간 : cv2.COLOR_BGR2RGB\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        bboxes, confs, points = model.predict(frame)\n",
    "\n",
    "        if not status:\n",
    "            print(\"Could not read frame\")\n",
    "            exit()\n",
    "\n",
    "        for idx in range(len(bboxes[0])):\n",
    "\n",
    "            (startX, startY)=bboxes[0][idx][0], bboxes[0][idx][1]\n",
    "            (endX, endY)=bboxes[0][idx][2], bboxes[0][idx][3]\n",
    "        \n",
    "            # ---------------------------------------------------------------------------------\n",
    "            # cv2.rectangle <- 사각형 그리기 함수 파라미터\n",
    "            # 입력 이미지 : frame \n",
    "            # 좌측 상단 모서리 좌표 : (startX, startY)\n",
    "            # 우측 하단 모서리 좌표 : (endX, endY)\n",
    "            # 색상 : (0, 255, 0)\n",
    "            # 두께 : 2\n",
    "            # ---------------------------------------------------------------------------------\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "        # display output\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow(\"Real-time face detection\", frame)  # 윈도우 창에 이미지를 띄움\n",
    "\n",
    "        # cv2.waitkey 키 입력 대기 함수\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q' 키 입력 받으면 윈도우 창이 종료\n",
    "            break\n",
    "        \n",
    "\n",
    "    webcam.release()  # 동영상 파일을 닫고 메모리 해제\n",
    "    cv2.destroyAllWindows()   # 모든 윈도우 창을 닫음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "from yolov5facedetector.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 기    능 : 얼굴 인식 네모 박스 함수\n",
    "# 함 수 명 : nemo\n",
    "# 파라미터 : url\n",
    "# 반 환 값 : 없음\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def nemo(best=0):\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # YoloDetector 파라미터 \n",
    "    # gpu : gpu number (int) or -1 or string for cpu.\n",
    "    # min_face : minimal face size in pixels.\n",
    "    # target_size : target size of smaller image axis (choose lower for faster work). e.g. 480, 720, 1080. None for original resolution.\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    model = YoloDetector(target_size=1080, gpu=0, min_face=0)  # yolov5n_state_dict.pt 자동 다운 됨\n",
    "\n",
    "    # 경로 url의 비디오 정보를 반환\n",
    "    try:\n",
    "        webcam=cv2.VideoCapture(best.url)\n",
    "    except:\n",
    "        webcam = cv2.VideoCapture(0)\n",
    "\n",
    "    # 동영상 파일 열기 성공 여부 확인\n",
    "    if not webcam.isOpened():\n",
    "        print(\"Could not open webcam\")  # 열려있지 않으면 문자열 출력\n",
    "        exit()\n",
    "        \n",
    "    # 비디오 매 프레임 처리\n",
    "    while webcam.isOpened():\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # webcam.read <- 프레임 읽기 메서드\n",
    "        # status : 카메라의 상태가 저장. 정상 작동 True, 비정상 작동 False 반환\n",
    "        # frame : 현재 시점의 프레임(numpy.ndarray) 저장\n",
    "        # -------------------------------------------------------------\n",
    "        status, frame = webcam.read() \n",
    "        # -------------------------------------------------------------\n",
    "        # cv2.resize <- 이미지 크기 조절 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 절대 크기 : dsize \n",
    "        # 상대 크기 : fx, fy\n",
    "        # interpolation : 보간법\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # cv2.cvtcolor <- 색상 공간 변환 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 색상 변환 코드. 원본 이미지 색상 공간2결과 이미지 색상 공간 : cv2.COLOR_BGR2RGB\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        bboxes, confs, points = model.predict(frame)\n",
    "\n",
    "        if not status:\n",
    "            print(\"Could not read frame\")\n",
    "            exit()\n",
    "\n",
    "        for idx in range(len(bboxes[0])):\n",
    "\n",
    "            (startX, startY)=bboxes[0][idx][0], bboxes[0][idx][1]\n",
    "            (endX, endY)=bboxes[0][idx][2], bboxes[0][idx][3]\n",
    "        \n",
    "            # ---------------------------------------------------------------------------------\n",
    "            # cv2.rectangle <- 사각형 그리기 함수 파라미터\n",
    "            # 입력 이미지 : frame \n",
    "            # 좌측 상단 모서리 좌표 : (startX, startY)\n",
    "            # 우측 하단 모서리 좌표 : (endX, endY)\n",
    "            # 색상 : (0, 255, 0)\n",
    "            # 두께 : 2\n",
    "            # ---------------------------------------------------------------------------------\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "        # display output\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow(\"Real-time face detection\", frame)  # 윈도우 창에 이미지를 띄움\n",
    "\n",
    "        # cv2.waitkey 키 입력 대기 함수\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q' 키 입력 받으면 윈도우 창이 종료\n",
    "            break\n",
    "        \n",
    "\n",
    "    webcam.release()  # 동영상 파일을 닫고 메모리 해제\n",
    "    cv2.destroyAllWindows()   # 모든 윈도우 창을 닫음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import pafy\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "from yolov5facedetector.face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 기    능 : 얼굴 인식 네모 박스 함수\n",
    "# 함 수 명 : nemo\n",
    "# 파라미터 : best\n",
    "# 반 환 값 : 없음\n",
    "# -------------------------------------------------------------\n",
    "def nemo(best=0):\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # YoloDetector 파라미터 \n",
    "    # gpu : gpu number (int) or -1 or string for cpu.\n",
    "    # min_face : minimal face size in pixels.\n",
    "    # target_size : target size of smaller image axis (choose lower for faster work). e.g. 480, 720, 1080. None for original resolution.\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    model = YoloDetector(target_size=1080, gpu=0, min_face=0)  # yolov5n_state_dict.pt 자동 다운 됨\n",
    "\n",
    "    # 경로 url의 비디오 정보를 반환\n",
    "    try:\n",
    "        webcam=cv2.VideoCapture(best.url)\n",
    "    except:\n",
    "        webcam = cv2.VideoCapture(0)\n",
    "\n",
    "    # 동영상 파일 열기 성공 여부 확인\n",
    "    if not webcam.isOpened():\n",
    "        print(\"Could not open webcam\")  # 열려있지 않으면 문자열 출력\n",
    "        exit()\n",
    "        \n",
    "    # 비디오 매 프레임 처리\n",
    "    while webcam.isOpened():\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # webcam.read <- 프레임 읽기 메서드\n",
    "        # status : 카메라의 상태가 저장. 정상 작동 True, 비정상 작동 False 반환\n",
    "        # frame : 현재 시점의 프레임(numpy.ndarray) 저장\n",
    "        # -------------------------------------------------------------\n",
    "        status, frame = webcam.read() \n",
    "        # -------------------------------------------------------------\n",
    "        # cv2.resize <- 이미지 크기 조절 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 절대 크기 : dsize \n",
    "        # 상대 크기 : fx, fy\n",
    "        # interpolation : 보간법\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # cv2.cvtcolor <- 색상 공간 변환 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 색상 변환 코드. 원본 이미지 색상 공간2결과 이미지 색상 공간 : cv2.COLOR_BGR2RGB\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        bboxes, confs, points = model.predict(frame)\n",
    "\n",
    "        if not status:\n",
    "            print(\"Could not read frame\")\n",
    "            exit()\n",
    "\n",
    "        for idx in range(len(bboxes[0])):\n",
    "\n",
    "            (startX, startY)=bboxes[0][idx][0], bboxes[0][idx][1]\n",
    "            (endX, endY)=bboxes[0][idx][2], bboxes[0][idx][3]\n",
    "        \n",
    "            # ---------------------------------------------------------------------------------\n",
    "            # cv2.rectangle <- 사각형 그리기 함수 파라미터\n",
    "            # 입력 이미지 : frame \n",
    "            # 좌측 상단 모서리 좌표 : (startX, startY)\n",
    "            # 우측 하단 모서리 좌표 : (endX, endY)\n",
    "            # 색상 : (0, 255, 0)\n",
    "            # 두께 : 2\n",
    "            # ---------------------------------------------------------------------------------\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "        # display output\n",
    "        frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow(\"Real-time face detection\", frame)  # 윈도우 창에 이미지를 띄움\n",
    "\n",
    "        # cv2.waitkey 키 입력 대기 함수\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q' 키 입력 받으면 윈도우 창이 종료\n",
    "            break\n",
    "        \n",
    "\n",
    "    webcam.release()  # 동영상 파일을 닫고 메모리 해제\n",
    "    cv2.destroyAllWindows()   # 모든 윈도우 창을 닫음\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 기    능 : 유튜브 주소로 파일 실행하기\n",
    "# 함 수 명 : trans\n",
    "# 파라미터 : url\n",
    "# 반 환 값 : best 또는 없음\n",
    "# -------------------------------------------------------------\n",
    "def trans(url=0):\n",
    "    try:\n",
    "        video = pafy.new(url)\n",
    "        best = video.getbest(preftype='mp4')     # 'webm','3gp'\n",
    "\n",
    "        return best\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 유튜브 경로 입력\n",
    "url ='https://www.youtube.com/watch?v=Vhqhq8HwBwI'\n",
    "\n",
    "# 함수 호출\n",
    "try:\n",
    "    uurl = trans(url)\n",
    "except:\n",
    "    uurl = trans()\n",
    "\n",
    "nemo(uurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘못된 주소 입니다.\n"
     ]
    }
   ],
   "source": [
    "import pafy\n",
    "import cv2\n",
    "\n",
    "\n",
    "# youtube\n",
    "def youtu(url):\n",
    "    video = pafy.new(url)\n",
    "    best = video.getbest(preftype='mp4')     # 'webm','3gp'\n",
    "    \n",
    "    return best.url\n",
    "\n",
    "url = 'https://wutube.com/watch?v=hoRAV8Wp2UM&list=PLWotpcwXa04EWQri_ZZeTFG=12'\n",
    "try:\n",
    "    uurl = youtu(url)\n",
    "except:\n",
    "    print('잘못된 주소 입니다.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\vs코드\\wkit_vs\\study\\study_1110.ipynb 셀 13\u001b[0m in \u001b[0;36m<cell line: 140>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     webcam\u001b[39m.\u001b[39mrelease()  \u001b[39m# 동영상 파일을 닫고 메모리 해제\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()   \u001b[39m# 모든 윈도우 창을 닫음\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m mojaic(url)\n",
      "\u001b[1;32mc:\\Users\\USER\\Desktop\\vs코드\\wkit_vs\\study\\study_1110.ipynb 셀 13\u001b[0m in \u001b[0;36mmojaic\u001b[1;34m(url, yolo_type, target_size, gpu, min_face)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m status, frame \u001b[39m=\u001b[39m webcam\u001b[39m.\u001b[39mread() \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# -------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# cv2.resize <- 이미지 크기 조절 함수 파라미터\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# 입력 이미지 : frame\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m bboxes, confs, points \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m status:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Desktop/vs%EC%BD%94%EB%93%9C/wkit_vs/study/study_1110.ipynb#X15sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCould not read frame\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\yolov5facedetector\\face_detector.py:193\u001b[0m, in \u001b[0;36mYoloDetector.predict\u001b[1;34m(self, imgs, conf_thres, iou_thres)\u001b[0m\n\u001b[0;32m    190\u001b[0m     images \u001b[39m=\u001b[39m imgs\n\u001b[0;32m    191\u001b[0m origimgs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(images)\n\u001b[1;32m--> 193\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preprocess(images)\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode(): \u001b[39m# change this with torch.no_grad() for pytorch <1.8 compatibility\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector(images)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch38\\lib\\site-packages\\yolov5facedetector\\face_detector.py:110\u001b[0m, in \u001b[0;36mYoloDetector._preprocess\u001b[1;34m(self, imgs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m imgsz \u001b[39m=\u001b[39m check_img_size(\u001b[39mmax\u001b[39m(img\u001b[39m.\u001b[39;49mshape[:\u001b[39m2\u001b[39m]), s\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mstride\u001b[39m.\u001b[39mmax())  \u001b[39m# check img_size\u001b[39;00m\n\u001b[0;32m    111\u001b[0m img \u001b[39m=\u001b[39m letterbox(img, new_shape\u001b[39m=\u001b[39mimgsz)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    112\u001b[0m pp_imgs\u001b[39m.\u001b[39mappend(img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 모듈 로딩\n",
    "import pafy\n",
    "import cv2\n",
    "from yolov5facedetector.face_detector import YoloDetector\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=hoRAV8Wp2UM'\n",
    "\n",
    "# url = 'https://www.you?v=hoRAV8Wp2UM'   # 잘못된 경로\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 기    능 : 얼굴 모자이크 함수\n",
    "# 함 수 명 : mojaic\n",
    "# 파라미터 : best\n",
    "# 반 환 값 : 없음\n",
    "# -------------------------------------------------------------\n",
    "def mojaic(url,yolo_type='yolov5n',  target_size=1080, gpu=0, min_face=0):\n",
    "    \n",
    "    try:\n",
    "        video = pafy.new(url)\n",
    "        best = video.getbest(preftype='mp4')\n",
    "        uurl = best.url\n",
    "\n",
    "    except Exception as e:\n",
    "        uurl = ''\n",
    "        print('오류 =>\\n', e)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # YoloDetector 파라미터 \n",
    "    # gpu : gpu number (int) or -1 or string for cpu.\n",
    "    # min_face : minimal face size in pixels.\n",
    "    # target_size : target size of smaller image axis (choose lower for faster work). e.g. 480, 720, 1080. None for original resolution.\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    model = YoloDetector(yolo_type=yolo_type, target_size=target_size, gpu=gpu, min_face=min_face)  # yolov5n_state_dict.pt 자동 다운 됨\n",
    "\n",
    "    # 경로 url의 비디오 정보를 반환\n",
    "    \n",
    "    webcam = cv2.VideoCapture(uurl)\n",
    "\n",
    "    #재생할 파일의 넓이와 높이\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    width = round(webcam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = round(webcam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = webcam.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter('mosaic_chim.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    # 동영상 파일 열기 성공 여부 확인\n",
    "    if not webcam.isOpened():\n",
    "        print(\"Could not open webcam\")  # 열려있지 않으면 문자열 출력\n",
    "        exit()\n",
    "        \n",
    "    # 비디오 매 프레임 처리\n",
    "    while webcam.isOpened():\n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # webcam.read <- 프레임 읽기 메서드\n",
    "        # status : 카메라의 상태가 저장. 정상 작동 True, 비정상 작동 False 반환\n",
    "        # frame : 현재 시점의 프레임(numpy.ndarray) 저장\n",
    "        # -------------------------------------------------------------\n",
    "\n",
    "        status, frame = webcam.read() \n",
    "\n",
    "        # -------------------------------------------------------------\n",
    "        # cv2.resize <- 이미지 크기 조절 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 절대 크기 : dsize \n",
    "        # 상대 크기 : fx, fy\n",
    "        # interpolation : 보간법\n",
    "        # ---------------------------------------------------------------------------------\n",
    "\n",
    "        # frame=cv2.resize(frame, dsize=(0,0), fx=0.7, fy=0.7, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        # cv2.cvtcolor <- 색상 공간 변환 함수 파라미터\n",
    "        # 입력 이미지 : frame\n",
    "        # 색상 변환 코드. 원본 이미지 색상 공간2결과 이미지 색상 공간 : cv2.COLOR_BGR2RGB\n",
    "        # ---------------------------------------------------------------------------------\n",
    "\n",
    "        # frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        bboxes, confs, points = model.predict(frame)\n",
    "\n",
    "        if not status:\n",
    "            print(\"Could not read frame\")\n",
    "            exit()\n",
    "\n",
    "        for bbox in bboxes[0]:\n",
    "\n",
    "            (startX, startY)=bbox[0], bbox[1]\n",
    "            (endX, endY)=bbox[2], bbox[3]\n",
    "        \n",
    "            # ---------------------------------------------------------------------------------\n",
    "            # cv2.rectangle <- 사각형 그리기 함수 파라미터\n",
    "            # 입력 이미지 : frame \n",
    "            # 좌측 상단 모서리 좌표 : (startX, startY)\n",
    "            # 우측 하단 모서리 좌표 : (endX, endY)\n",
    "            # 색상 : (0, 255, 0)\n",
    "            # 두께 : 2\n",
    "            # ---------------------------------------------------------------------------------\n",
    "\n",
    "            # cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "            # 모자이크 처리\n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            M = face_region.shape[0]\n",
    "            N = face_region.shape[1]\n",
    "\n",
    "            try: \n",
    "                face_region = cv2.resize(face_region, None, fx=0.05, fy=0.05, interpolation=cv2.INTER_AREA)\n",
    "                face_region = cv2.resize(face_region, (N, M), interpolation=cv2.INTER_AREA)\n",
    "                frame[startY:endY, startX:endX] = face_region\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "\n",
    "        # display output\n",
    "\n",
    "        # frame=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"Real-time face detection\", frame)  # 윈도우 창에 이미지를 띄움\n",
    "\n",
    "        \n",
    "\n",
    "        # cv2.waitkey 키 입력 대기 함수\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q' 키 입력 받으면 윈도우 창이 종료\n",
    "            break\n",
    "        \n",
    "    out.release()\n",
    "    webcam.release()  # 동영상 파일을 닫고 메모리 해제\n",
    "    cv2.destroyAllWindows()   # 모든 윈도우 창을 닫음\n",
    "\n",
    "\n",
    "mojaic(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e713db361fd0c0a151521921a307db5316dc01e9b741659f15d8bea985d071ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
