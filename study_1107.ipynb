{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [YOLOv5] YOLO를 이용한 Object Detection\n",
    "\n",
    "### https://ssong915.tistory.com/43\n",
    "\n",
    " YOLOv5란?\n",
    "\n",
    " You Only Look Once 의 약자로 Object detection 분야에서 많이 알려진 모델\n",
    " 처음을 one-stage-detection 방법을 고안하여 실시간으로 Object Detection이 가능하게 만들었다.\n",
    "\n",
    " YOLOv5 특징\n",
    " 1. 이미지 전체를 한번만 보는 것\n",
    " R-CNN: 이미지를 여러장으로 분할하고 CNN 모델을 이용하여 이미지를 분석했다.\n",
    " 따라서 이미지 한장을 보더라도 여러장의 이미지를 분석하는 것과 같았다.\n",
    " 하지만 YOLO는 이러한 과정없이 이미지를 한 번만 보는 특징을 가지고 있다.\n",
    "\n",
    " 2. 통합된 모델을 사용하는 것\n",
    " 기존 Object Detection 모델은 전처리모델 + 인공신경망을 결합하여 사용했다.\n",
    " 하지만 YOLO에서는 위를 통합한 모델을 사용\n",
    "\n",
    " 3. 실시간으로 객체를 탐지할 수 있는 것\n",
    " 기존의 R-NN보다 6배 빠른 성능을 보여줌\n",
    "\n",
    " Object Detection의 구조와 종류\n",
    "\n",
    " 최신 detector 는 주로 백본과 헤드라는 두 부분으로 구성됨\n",
    "\n",
    "- 백본(Backbone)은 입력이미지를 feature map으로 변형시켜주는 부분이다.\n",
    "- 헤드(Head)는 Backbone에서 추출한 feature mao의 location 작업을 해주는 부분으로, predict classes와 bounding boxes 작업이 수행된다. 헤드는 크게 Dense Prediction과 Sparse Prediction으로 나누어 진다.\n",
    "Sparse Prediction을 사용하는 Two-Stage Detector: Predict Classes 와 Bounding Box Regression 분리 ex) R-CNN, R-FCN Dence Prediction을 사용하는 One-Stage Detector: Predict Classes 와 Bounding Box Regression 통합 ex) YOLO, SSD\n",
    "넥(Neck)은 Backbone과 Head를 연결하는 부분으로, feature map을 정제하고 재구성한다.\n",
    "\n",
    "- 절차\n",
    "\n",
    "input(이미지) -> CNN -> FC(Fully Connected) -> PT(Prediction Tensor)를 반복\n",
    "\n",
    "1. 이미지를 S*S의 그리드로 분할 (논문에서는 7*7)\n",
    "\n",
    "그리드마다 하나의 객체를 예측한다. 미리 설정해 둔 경계를 통해서 객체의 위치와 크기를 파악한다. 여러 객체가 한 셀에 있으면 탐지를 못할 수도 있다. 각 Grid cell 은 조건이 있다.\n",
    "- B개의 boundary boxes를 예측하고, 각 box는 하나의 box confidence score을 가지고 있다.\n",
    "- 예측된 box 수에 관계 없이 단 하나의 객체만 탐지한다.\n",
    "- boundary box 는 객체의 위치 (x,y), 객체의 크기(w,h), box confidence score로 구성된다.\n",
    "- box confidence score는 box가 객체를 포함하고 있을 가능성을 반영함\n",
    "\n",
    "- C개의 conditional class probabailities를 에측한다.\n",
    "- 탐지된 객체가 어느 특정 클래스에 속하는 지에 대한 확률\n",
    "\n",
    "2. 이미지 전체를 신경망에 넣고 특징 추출을 통해 예측 텐서(Prediction Tensor) 생성\n",
    "- S*S*(B*5+C)\n",
    "- 7*7 grids, 2 boundary boxes, 20 classes = 7*7*30\n",
    "- 이제 YOLO는 7730 텐서를 예측하는 CNN 네트워크를 구축해야한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5의 장점\n",
    "\n",
    "##### https://velog.io/@dkddkkd55/Yolov5%EC%9D%98-%EC%9E%A5%EC%A0%90\n",
    "\n",
    "YOLOv5의 장점\n",
    "- YOLOV5는 모델 탐지의 정확도가 높고, 초당 최대 140프레임으로,\n",
    "연산 속도가 매우 빠르다.\n",
    "- 또한, YOLOv5는 모델의 가중치 파일 크기도 YOLOv4 보다 작아서 실시간 탐지를 구현하기에 더 적합하다.\n",
    "- YOLOv5 네트워크의 장점은 (1) high detection accuracy(높은 탐지의 정확도), (2) lightweight characteristics(경량화 특성), (3) fast detection speed at the same time(빠른 속도로 탐지)]\n",
    "\n",
    "YOLO5의 4가지 아키텍처\n",
    "- YOLOv5s, YOLOv5m, YOLOv5l, YOLOv5x\n",
    "- 4가지 아키텍처 차이점:\n",
    "네트워크의 특정 위치에 있는 특징 추출 모듈과 convolution kernel의 양이 다르며, 모델의 크기와 모델 매개변수 양이 차례로 증가한다.\n",
    "\n",
    "YOLO의 발전\n",
    "- YOLO 시리즈는 1~5로 구성되어 있으며, YOLOv1은 R-CNN을 기반으로 개발되었다.\n",
    "- R-CNN(Region Proposals + CNN)은 타겟 탐지를 위해 컨볼루션 신경망을 사용함과 동시에 예측 분류를 위해 SVM(support vector machine)을 추가하는 것이다.\n",
    "- R-CNN(Region Proposals + CNN)은 위치 감지 및 물체 분류 정확도가 매우 높지만, 연산량이 많고 검출 속도가 매우 느리다.\n",
    "- YOLOv1? 입력 이미지는 한 번만 처리되고(YOLO 이름의 유래), 여러 컨볼루션 레이어를 통해 서로 다른 특징을 추출하고 매번 컨볼루션 커널 매개변수를 공유한다. 이미지 감지 속도가 매우 빠르다. 따라서 장점은 (1) 이전 탐지 모델보다 빠르다.\n",
    "(2) 실시간 요구 사항을 충족할 수 있다.\n",
    "단점은 (1) 위치 감지 정확도가 낮고 (2) 작은 물체를 감지할 수 없다.\n",
    "- YOLOv2? - YOLOV1 백본 네트워크가 업그레이드된 것으로, 평균 풀링, SoftMax 분류 및 Anchor 예측 상자를 사용한다. 또한 표적 분류와 탐지를 결합한 훈련 방법을 제안한다. 따라서 장점은 정확도 향상 단점은 작은 물체 감지의 경우, 작은 물체의 감지 정확도가 높지 않다.\n",
    "- YOLOv3? - YOLOv3의 컨볼루션 레이어는 YOLOv2의 약 2.8배이며 네트워크의 깊이와 두께를 증가시켜 모델 정확도를 높인다. SoftMax 분류기는 여러 Logistic 분류기로 대체된다.\n",
    "- YOLOv4 (2019년)? 주요 목적은 실제 작업 환경에 적용할 수 있고 병렬로 최적화할 수 있는 빠른 표적 탐지 시스템을 설계하는 것이다.\n",
    "- YOLOv5? YOLOv5는 YOLOv4를 기반으로 개선되었으며 실행 속도가 크게 향상되어 가장 빠른 속도가 초당 140프레임에 도달한다. YOLOv5의 크기는 작고 가중치 파일은 YOLOv4보다 거의 90% 작아 YOLOv5를 임베디드 장치에 배포할 수 잇다. YOLOv4와 비교하여 YOLOv5는 정확도가 더 높고 작은 물체를 인식하는 능력이 더 우수하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
